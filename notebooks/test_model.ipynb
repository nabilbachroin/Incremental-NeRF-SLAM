{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c31d481-624b-4b5c-8507-c43c9fcd58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1284457e-a71f-4f7c-9720-fb05e751d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "from train import NeRFSystem\n",
    "from models.nerf import Embedding, NeRF\n",
    "from models.rendering import render_rays\n",
    "from datasets.blender import BlenderDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da3b81a-a1e1-4927-a7e4-f26ccd5e1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = edict(\n",
    "            root_dir = \"/scratch/saksham/data/nerf_synthetic/lego/\",\n",
    "            dataset_name = \"blender\",\n",
    "            N_samples = 64,\n",
    "            N_importance = 128,\n",
    "            loss_type = \"mse\",\n",
    "            batch_size = 1024,\n",
    "            chunk = 32*1024,\n",
    "            use_disp = True,\n",
    "            perturb = True,\n",
    "            noise_std = 1.0\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c958044-4809-4745-a5c6-1230653460af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths \n",
    "blender_data_path = \"/scratch/saksham/data/nerf_synthetic/lego/\"\n",
    "train_dataset = BlenderDataset(root_dir = blender_data_path, split = \"train\")\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4,\n",
    "                          batch_size= hparams.batch_size,\n",
    "                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd00391e-79dd-4389-bdce-682ceda3028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4157d696-91d1-49ef-86d6-8a327071a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa2d7c46-55af-4633-b0c7-36d14f8995c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 8]), torch.Size([1024, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rays, rgbs = batch['rays'], batch['rgbs']\n",
    "rays.shape, rgbs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2acbb17-86e4-46d5-9d07-c9161ca2476f",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf19c176-de42-4097-9e69-3a02843c3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_xyz = Embedding(3, 10) # 10 is the default number\n",
    "embedding_dir = Embedding(3, 4) # 4 is the default number\n",
    "\n",
    "embeddings = {'xyz': embedding_xyz,\n",
    "              'dir': embedding_dir}\n",
    "\n",
    "nerf_coarse = NeRF()\n",
    "models = {'coarse' : nerf_coarse}\n",
    "\n",
    "if hparams.N_importance > 0:\n",
    "    nerf_fine = NeRF()\n",
    "    models['fine'] = nerf_fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ff703-9ee3-4058-8093-3bef903badc5",
   "metadata": {},
   "source": [
    "### Model Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f600af5-52ec-4226-9499-48096626e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = rays.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f51e994-1bd3-4aec-a1a0-91ff6e7d2608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 8])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27f7fe87-d06d-4395-95b9-37ea784d78e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "results = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a830f3-8967-4a80-ab13-d461aa1972fd",
   "metadata": {},
   "source": [
    "**Inputs:**\n",
    "- models: list of NeRF models (coarse and fine) defined in nerf.py \n",
    "- embeddings: list of embedding models of origin and direction defined in nerf.py \n",
    "- rays: (N_rays, 3+3+2), ray origins and directions, near and far depths \n",
    "- N_samples: number of coarse samples per ray \n",
    "- use_disp: whether to sample in disparity space (inverse depth) \n",
    "- perturb: factor to perturb the sampling position on the ray (for coarse model only)\n",
    "- noise_std: factor to perturb the model's prediction of sigma\n",
    "- N_importance: number of fine samples per ray\n",
    "- chunk: the chunk size in batched inference \n",
    "- white_back: whether the background is white (dataset dependent) \n",
    "- test_time: whether it is test (inference only) or not. If True, it will not do inference\n",
    "                   on coarse rgb to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47ac2cf9-67c6-40bc-b95f-328ca0f108b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, B, hparams.chunk):\n",
    "    rendered_ray_chunks = \\\n",
    "        render_rays(models,\n",
    "                    embeddings,\n",
    "                    rays[i:i + hparams.chunk],\n",
    "                    hparams.N_samples,\n",
    "                    hparams.use_disp,\n",
    "                    hparams.perturb,\n",
    "                    hparams.noise_std,\n",
    "                    hparams.N_importance,\n",
    "                    hparams.chunk, # chunk size is effective in val mode\n",
    "                    train_dataset.white_back)\n",
    "\n",
    "    for k, v in rendered_ray_chunks.items():\n",
    "        results[k] += [v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2c7e5ae-6d57-46e5-89da-2e97aea0a019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weights_coarse', 'opacity_coarse', 'z_vals_coarse', 'rgb_coarse', 'depth_coarse', 'weights_fine', 'opacity_fine', 'z_vals_fine', 'rgb_fine', 'depth_fine'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1bef6e25-fe8b-418b-9562-923485daff70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 64])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['weights_coarse'][0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
